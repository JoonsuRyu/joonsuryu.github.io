<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-02-22T23:49:30+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">KEEPMIND</title><subtitle>A place I record so that I don&apos;t forget.</subtitle><author><name>Joonsu Ryu</name></author><entry><title type="html">Error and Noise</title><link href="http://localhost:4000/studies/error-and-noise/" rel="alternate" type="text/html" title="Error and Noise" /><published>2019-08-09T00:00:00+09:00</published><updated>2019-08-09T00:00:00+09:00</updated><id>http://localhost:4000/studies/error-and-noise</id><content type="html" xml:base="http://localhost:4000/studies/error-and-noise/">&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-02.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4장에서는 Error와 Noise에 대해 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;outline&quot;&gt;Outline&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-03.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번 장의 구성은 총 4개로 나뉩니다.&lt;/p&gt;

&lt;p&gt;먼저 지난 장 마지막에 다루었던 Nonlinear Transformation에 대해 좀 더 이야기해보고, 다음으로 Error를 측정하는 방법, 그리고 Noise가 발생하는 이유와 모델에 적용하는 법, 마지막으로 앞으로 이런 문제를 어떻게 접근할지에 대한 간단한 정리를 하며 마치게 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;nonlinear-transformation-continued&quot;&gt;Nonlinear transformation (continued)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-04.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;지난 장에서 배웠던 Nonlinear transformation의 과정을 한번 정리해봅시다. 이 문제가 시작된 이유는 Orginal data가 선형으로 분리가 불가능하여 우리가 배웠던 Linear Model을 직접적으로 적용할 수 없는 문제들이 존재했기 때문입니다. 그래서 이 문제를 어떻게 해결할지 고민하다가, Linear Model에서 “Linear”가 어디에 Linear 한 것이지를 생각해보았었죠. 여기서 Linear 하다는 것은 Input data $\mathbf{x}$에 Linear 한 것이 아니라 Weight Vector $\mathbf{w}$에 Linear 한 것이라고 배웠습니다. 이를 통해 Input data $\mathbf{x}$는 우리의 입맛에 맞게 Transform을 시켜도 문제가 없겠구나라는 결론에 도달한 것입니다. 따라서 기존의 Input data들이 $\mathcal{X}$라는 공간에 있다고 가정했을 때, 이들을 적절한 함수인 $\Phi$로 Transform 시켜서 선형으로 분리가 가능하게끔 만들어 줬습니다. 이때, Input data들을 $\Phi$로 Transform 시킨 공간을 $\mathcal{Z}$라 부르겠습니다.&lt;/p&gt;

&lt;p&gt;이렇게 선형 독립이 가능한 공간인 $\mathcal{Z}$에서 기존에 우리가 알고있던 Linear Model을 적용해 문제를 해결했습니다. 예를 들면 PLA 같은 방법으로 말입니다. 그렇게 알고리즘을 수행 후 나온 결과는 $\mathcal{Z}$ 공간에서 정의된 Final Hypothesis $\tilde{g}$가 나오게 됩니다. (기존의 Input data가 존재하는 $\mathcal{X}$ 공간에서의 Final Hypothesis와의 차이를 두기 위해 $g$가 아니라 $\tilde{g}$라고 적은 겁니다. $\tilde{g}$는 ‘틸다 g’라고 읽습니다) 이때의 결과를 수식으로 표현하자면 $\tilde{g}(\mathbf{z})=sign(\tilde{\mathbf{w}}^{\sf T}\mathbf{z})$ 라고 쓸 수 있습니다. 하지만 우리가 원하는 결과는 $\tilde{g}$가 아니라 $g$ 입니다.&lt;/p&gt;

&lt;p&gt;따라서 $\tilde{g}$를 초기에 했던 Transform $\Phi$의 역함수인 $\Phi^{-1}$로 Transform을 하게 되면 우리가 원하던 $g$가 나오게 됩니다. 단, $\mathcal{Z}$ 공간에서는 선형으로 $\tilde{g}$를 구하긴 했지만 원래의 $\mathcal{X}$ 공간에서 $g$는 선형으로 나오지 않습니다. (이해를 돕기 위해 $\Phi^{-1}$를 사용해서 $g$를 구하는 것처럼 설명했지만, 실제로는 이렇게 하지 않고 그냥 Input data $\mathbf{x}$를 $\Phi$로 Transform 해서 계산합니다. 왜 그런지는 다음 슬라이드에서 설명드리겠습니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-05.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그렇다면 Transform $\Phi$를 통해서 과연 어떤 값들이 바뀌게 되는지 하나하나 따져보겠습니다.&lt;/p&gt;

&lt;p&gt;먼저 Input data $\mathbf{x}$는 당연히 바뀌게 됩니다. $\mathbf{x}$가 바뀐다는 말은 $\mathbf{x}$ 벡터의 모든 값들이 $\Phi$를 거쳐 바뀌게 된다는 겁니다. (ex. $x_0 \to z_0$) 하지만 Output인 $y$는 바뀌지 않습니다. +1로 판단한 것은 그대로 +1, -1로 판단한 것은 그대로 -1로 남아야만 원래의 문제를 그대로 풀 수 있기 때문입니다. 이는 Regression에서도 마찬가지입니다.&lt;/p&gt;

&lt;p&gt;Weight를 구하는 것이 목적이니 이것이 가장 중요한데, $\mathcal{X}$ 공간에서 직접적으로 Weight를 구하지 않기 때문에 $\mathcal{X}$ 공간에서의 Weight Vector는 존재하지 않습니다. Weight를 계산한 것은 $\mathcal{Z}$ 공간이니 $\tilde{\mathbf{w}}$ 만 존재합니다. 하지만 우리가 갖고있는 것은 $\mathbf{x}$이고 $g$를 이용해서 classification/regression을 사용해야 하니 $g(\mathbf{x})$를 아래와 같이 정의합니다.&lt;/p&gt;

\[g(\mathbf{x}) = sign(\tilde{\mathbf{w}}^{\sf T}\mathbf{z}) = sign(\tilde{\mathbf{w}}^{\sf T}\Phi(\mathbf{x}))\]

&lt;p&gt;여기서 “아니 그냥 $\tilde{\mathbf{w}}$에 $\Phi^{-1}$를 취해서 $\mathbf{w}$를 구하면 되는거 아닌가? 왜 이렇게 불편하게 $g$를 계산하지?” 라는 의문을 가질 수도 있습니다. 물론 그 방법이 더 간단합니다만, $\Phi^{-1}$가 존재하지 않을 수 있다는 것이 문제입니다. 예를 들어 만약에 Transform $\Phi$를 통해서 차원이 늘어난다면, 하나의 $\mathcal{Z}$ 공간의 좌표인 $\mathbf{z}$에서 여러 개의 $\mathbf{x}$와 대응할 수 있는 문제가 발생합니다. 따라서 조금 불편하더라도 $g$를 계산할 때 Input data를 $\Phi$로 Transform 할 수밖에 없는 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;error-measures&quot;&gt;Error measures&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-06.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다음으로 Error Measure에 대해 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-07.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Error Measure를 하기 전에 기존에 배웠던 Learning Diagram을 다시 살펴봅시다. 간단하게만 다시 설명드리면, Input Data $\mathbf{x}$는 어떤 확률 분포에 의해 생성되고, Target Function $f$에 의해 $y$값이 결정되어 Training Example $(\mathbf{x}_i, y_i)$가 생성된다고 가정합니다. 그 후 여러 개의 Hypothesis Set (ex. Perceptron)을 통해 Learning Algorithm (ex. PLA)을 거쳐 $f$와 가장 가까운 Final Hypothesis $g$를 얻는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-08.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그렇다면 $h$와 $f$가 가깝다($h \approx f$)는 어떻게 정의해야 할까요?&lt;/p&gt;

&lt;p&gt;이를 정량적으로 측정하기 위해 Error Measure $E(h, f)$를 정의합니다. 다만 직접적으로 두 함수 $h$와 $f$를 구할 수가 없기 때문에, Input data $\mathbf{x}$를 넣었을 때의 값의 차이로 정의하게 됩니다. 이 때, $\mathbf{x}$는 함수 $h$, $f$의 한 “점”으로 볼 수 있기 때문에 이를 pointwise로 정의한다고 부릅니다.&lt;/p&gt;

&lt;p&gt;그런데, 우리는 이미 Error Measure 방법 중 두 가지를 배웠습니다. Linear Regression에서는 $h$와 $f$의 함수값의 차이의 제곱으로 정의한 Squared Error로 정의했고, Linear Classification에서는 맞았는가/틀렸는가를 비교했기 때문에 Binary Error를 사용하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-09.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;점 $\mathbf{x}$에서 각각 에러를 계산하는 것은 이렇게 간단합니다. 하지만 우리가 원하는 것은 각각 점에서의 에러가 아니라, $h$의 전체적인 에러입니다. 즉, 함수 $h$가 함수 $f$와 얼마나 다른가를 알고싶다는 것입니다.&lt;/p&gt;

&lt;p&gt;가장 간단한 방법으로 Error의 평균값을 사용합니다. In sample Error와 Out of sample Error 모두 평균값을 사용합니다만, 여기서도 In sample Error야 우리가 갖고있는 데이터를 사용해서 구하면 되지만, Out of sample Error는 어떻게 구해야 하는지에 대한 의문이 생깁니다. 이 방법은 다음 장에서 다루도록 하고, 우선은 전체적인 Error는 Sample의 평균 Error를 사용한다는 것만 짚고 넘어갑시다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-10.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Learning Diagram에서 Error를 포함한 그림입니다. Error를 측정할 때 각각 $\mathbf{x}$ 점에서의 $h$와 $f$의 함수값의 차이의 평균으로 계산한다고 말씀드렸습니다. 여기서 $\mathbf{x}$는 특정한 확률 분포로부터 생성된 점이기 때문에 위의 그림과 같이 표현됨을 알 수 있습니다. Final Hypothesis $g$는 이 Error의 평균값이 가장 낮은 Hypothesis로 결정됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-11.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 이 Error Measure를 어떻게 결정해야 하는지도 중요합니다. 기존의 Error Measure 방법은 Squared Error와 Binary Error를 다루었습니다만, 이 둘은 일부일 뿐 모든 상황에 적용할 수 있는 방법이 아닙니다.&lt;/p&gt;

&lt;p&gt;예를 들어, 기계학습으로 지문을 인식하는 프로그램을 구현했다고 가정해봅시다. 기계학습은 완벽하지 못하기 때문에, 아무리 완벽에 가깝게 구현했다고 할지라도 Error가 발생할 수 있습니다. 이 경우 발생할 수 있는 에러는 2가지입니다. &lt;span style=&quot;color:red&quot;&gt;False Accept Error&lt;/span&gt;는 등록되지 않은 지문을 정상으로 판단하는 오류이고, &lt;span style=&quot;color:red&quot;&gt;False Reject Error&lt;/span&gt;는 정상으로 등록된 지문을 침입자로 판단하는 오류입니다.&lt;/p&gt;

&lt;p&gt;그렇다면 각각의 상황에서 어느정도의 페널티를 주는 것이 적당할까요? 이 문제는 Classification이기 때문에 그냥 Binary Error를 사용하면 된다고 생각하실 수도 있습니다만, 다음 두 가지 예시를 통해 그렇게 간단한 문제가 아님을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-12.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 지문 인식 프로그램이 마트에 설치되어 있다고 가정해봅시다. 마트에서는 지문이 등록된 회원들에게 할인해주는 이벤트를 하고 있습니다. 이 상황에서 발생할 수 있는 두 가지 Error에 대해 어떻게 페널티를 주어야 하는지 생각해봅시다.&lt;/p&gt;

&lt;p&gt;만약 마트의 회원이 할인 이벤트로 인해 마트에 갔는데 False Reject가 발생하여 컴퓨터가 지문을 제대로 인식 못해 몇번이나 손을 갖다대야 하는 상황이 온다면 그 고객은 몹시 기분이 나쁠 것입니다. 최악의 경우에는 단골 고객을 잃을 수도 있습니다. 다만 반대로, 우연히 지나가다 마트에 들른 비회원이 심심해서 지문을 갖다댔는데 컴퓨터가 회원으로 인식해서 할인을 해주는 상황(False Accept)은 마트 입장에서 크게 문제가 아닙니다. 마트는 그냥 약간의 금전적인 손해만 보고, 새로운 고객을 유치할 기회를 얻을 수도 있습니다. 이런 상황에서는 False Reject에 큰 패널티를 부여하고, False Accept는 그보다 낮은 페널티를 부여하는 것이 적절할 것입니다. 하지만 다른 상황에서도 마찬가지일까요?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-13.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번에는 이 지문 인식 프로그램이 국가정보원에 설치되어 있다고 가정해봅시다. 국가정보원의 1급 비밀이 담긴 금고는 요원들의 지문을 통해서만 열립니다. 만약 여기서 False Accept가 발생한다면 엄청난 문제가 발생할 수 있음을 알 수 있습니다. 최악의 경우에는 간첩의 지문만으로 금고가 열려서 국가 기밀이 노출되는 상황이 발생하겠죠.&lt;/p&gt;

&lt;p&gt;하지만 False Reject는 그다지 큰 문제가 아닙니다. 요원의 경우 이게 직업이고, 컴퓨터가 몇번 인식 못한다고 해도 툴툴대며 다시 손가락을 갖다댈 것이니까요. 따라서 이 경우에는 False Accept에 큰 패널티를 부여하고, False Reject는 그보다 낮은 페널티를 부여하는 것이 적절할 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-14.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 두 가지 상황을 통해, 같은 문제라도 상황에 따라 다른 Error Measure를 적용해야 함을 알 수 있습니다. 그런데 만약에 이렇게 구체적인 Error Measure를 사용할 수 없을 때는 어떻게 해야 할까요?&lt;/p&gt;

&lt;p&gt;크게 두 가지가 있습니다. &lt;span style=&quot;color:red&quot;&gt;Plausible Measure&lt;/span&gt;는 “Error가 특정한 분포를 따를 것이다” 라고 가정하는 것입니다. 가령 어떤 문제에서 Error가 가우시안 분포를 따른다라고 가정하는 것이죠. &lt;span style=&quot;color:red&quot;&gt;Friendly Measure&lt;/span&gt;는 수학적인 방법으로 Error를 계산하는 방법입니다. Closed-form을 통해 답을 구하거나, Convex Optimization을 통해 답을 구하는 방법입니다.&lt;/p&gt;

&lt;p&gt;온라인 강의에서도 이 방법들에 대해서는 그냥 이렇게만 설명만 하고 지나갔었기 때문에, 그냥 이러이러한 것이 있구나라고만 알고 넘어가시면 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-15.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;방금 배운 Error Measure를 Learning Diagram에 적용한 그림입니다. Learning Algorithm에서 Error Measure를 통해 Fianl Hypothesis를 도출한다는 것을 표현한 것이 추가된 그림입니다.&lt;/p&gt;

&lt;h2 id=&quot;noisy-targets&quot;&gt;Noisy targets&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-16.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 Noise Target이라는 것이 무엇인지 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;지금까지 우리가 구해야하는 목표를 “Target Function”이라고 표현했지만, 사실 이 Target Function은 Function이 아닐 수도 있습니다. (Function이 아니라는 것은 하나의 데이터에 대해서 여러 가지 값이 나올 수도 있다는 말입니다.)&lt;/p&gt;

&lt;p&gt;지난번에 사용했던 카드 발급 문제를 예를 들면, 이 카드 회사에는 지금까지 고객의 정보를 기반으로 카드를 방급해 주었는지/거절했는지를 판단한 데이터가 있습니다. 이 데이터중에서는 우연히 고객의 정보가 동일한 케이스도 있을 것입니다. 그런데 카드 발급 여부를 결정한 사람이 다르다던가, 같은 사람이라도 그날의 기분이 좋고/나쁘고의 이유로 인해 한명에게는 카드를 발급해주고, 다른 한명에게는 거절한 경우가 있을 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-17.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그래서 이제는 Target “Function” 이라는 표현 대신에 Target “Distribution” 이라고 표현할 것입니다. 즉, $y=f(\mathbf{x})$ 라는 표현 대신에 $P(y \mid \mathbf{x})$라는 표현을 쓰겠다는 얘기입니다. $P(y \mid \mathbf{x})$는 Input data가 $\mathbf{x}$일 때 $y$라는 결과가 나올 확률을 의미합니다. 그런데 Input data $\mathbf{x}$도 어떤 확률 분포에 의해 생성된다고 했으니 (Learning Diagram 참고) Input data $\mathbf{x}$가 생성될 확률을 $P(\mathbf{x})$라 할 수 있습니다. 따라서 종합적으로 $(\mathbf{x}, y)$라는 데이터가 생성될 확률은 $P(\mathbf{x})P(y \mid \mathbf{x})$ 라고 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;이를 토대로 Noisy target를 정의해 보면 deterministic target $f(\mathbf{x})$를 평균적인 값 $\mathbb{E}(y \mid \mathbf{x})$로 정의했을 때 output $y$와 $f(\mathbf{x})$의 차이라고 볼 수 있습니다. Deterministic target이란 Noise가 하나도 없는 target이라는 뜻입니다. (즉, 우리가 원래 알고있던 Target Function과 동일합니다)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-18.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 Noise를 반영한 Learning Diagram입니다. 자꾸 아까부터 Learning Diagram에 하나씩 추가되어 짜증나실 수도 있는데 다행이 이 그림이 최종판입니다. 왼쪽 위의 Target Function이 Target Distribution으로 바뀌었습니다. Target Distirubution이라는 것은 Target Function에 Noise를 추가한 것으로 보시면 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-19.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번엔 $P(y \mid \mathbf{x})$와 $P(\mathbf{x})$의 차이를 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;$P(y \mid \mathbf{x})$는 “데이터 $\mathbf{x}$가 들어왔을 때 Output $y$가 나올 확률”입니다. 실질적으로 우리가 학습하고 싶은 값이 됩니다. $P(\mathbf{x})$는 데이터 $\mathbf{x}$가 얼마나 자주 등장하는지를 나타냅니다. 특정한 데이터가 너무 자주 나오게 되면 학습 모델이 잘못될 수 있기 때문에 겉으로는 드러나지 않아도 이 값도 무시할 수는 없습니다. 이전 슬라이드에서 $(\mathbf{x}, y)$는 $P(\mathbf{x})P(y \mid \mathbf{x})$로 계산되었으니 이 두 가지 컨셉이 합쳐있음을 알 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;preamble-to-the-theory&quot;&gt;Preamble to the theory&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-20.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 이를 통해 앞으로 어떻게 접근할 것인지 간단하게 정리하고 마치겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-21.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2장에서 학습이 가능한가를 따졌을 때 In sample Error와 Out of sample Error를 최대한 비슷하게 만드는 것이 좋다고 하였습니다. 그런데 이걸 Learning이라고 말할 수 있을까요? 사실 Learning이라는건 Out of sample Error를 0에 가깝게 만드는건데, 이 두 표현이 같다고 볼 수는 없습니다. 극단적인 예시로 In sample Error와 Out of sample Error가 둘다 1이라고 해도 어쨌든 같아지기 때문입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-22.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 지금까지 배운 내용을 토대로 Out of sample Error를 0에 가깝에 유도할 수 있는 방법이 무엇인지 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;2장에서 In sample Error와 Out of sample Error를 최대한 비슷하게 만들어야 한다고 언급했었고, 3장에서 In sample Error를 0에 가깝게 만들어야 한다고 했습니다. 그렇다면 $0 \approx E_{in} \approx E_{out}$로 합치게 되면 Out of sample Error를 0에 가깝게 유도할 수 있음을 알 수 있습니다. 따라서 다음 장에서는 이 2가지를 각각 따로 다루게 될 예정입니다. $E_{out} \approx E_{in}$을 구하는 방법은 2개 장에 걸쳐 다룰 예정이고, $E_{in} \approx 0$은 4개 장에 걸쳐 다룰 예정입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/4. Error and Noise/ML 04-23.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;전체적인 그림은 위 슬라이드의 오른쪽 그림과 같습니다. In Sample Error가 0으로 다가갈수록 Out of Sample Error도 작아진다면 이상적이겠지만, 안타깝게도 In Sample Error를 어느정도까지 낮출 때는 Out of Sample Error도 낮아지지만, In Sample Error를 과도하게 0에 가깝게 맞추게 된다면 오히려 Out of sample Error가 커지는 문제가 있습니다. 왜냐하면 In Sample Error는 낮추려면 Model Complexity가 점점 높아지는데 이것은 Out of Sample Error를 높이기 때문입니다. (이것은 추후 Overfitting에서 더 자세히 다루게 될 예정입니다)&lt;/p&gt;

&lt;p&gt;따라서 Trading off를 정리해보면, Model Complexity가 높아질수록 In Sample Error가 낮아지지만, Out of Sample Error와 In Sample Error의 차이는 늘어난다는 관계가 있습니다. 그러므로 이를 적당히 조절할 수 있는 점을 찾는 것이 중요한데, 이는 VC dimension이라는 것으로 계산할 수 있습니다. VC dimension은 6장에서 다룰 예정입니다.&lt;/p&gt;

&lt;p&gt;이번 장은 여기까지입니다. 감사합니다.&lt;/p&gt;</content><author><name>Joonsu Ryu</name></author><category term="studies" /><category term="machine learning" /><summary type="html"></summary></entry><entry><title type="html">Linear Models I</title><link href="http://localhost:4000/studies/linear-models-1/" rel="alternate" type="text/html" title="Linear Models I" /><published>2019-08-02T00:00:00+09:00</published><updated>2019-08-02T00:00:00+09:00</updated><id>http://localhost:4000/studies/linear-models-1</id><content type="html" xml:base="http://localhost:4000/studies/linear-models-1/">&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-02.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;세 번째 챕터에서는 새로운 이슈인 선형 모델(Linear Model)에 대해서 알아보는 시간입니다.&lt;/p&gt;

&lt;p&gt;Introduction에서도 언급했었지만, 본 교재와 강의자료의 순서가 다른 부분이 조금 있는데, 오늘 할 Linear Models 부분이 바로 그런 부분입니다. 교재에서는 Linear Models 파트가 한 챕터로 묶여 있는데, 강의에서는 두 부분으로 나누어 앞부분을 챕터 3에 넣고, 뒷부분을 챕터 9에 배치하였습니다.&lt;/p&gt;

&lt;p&gt;왜 이렇게 만들었는가 궁금했는데, 강의영상에서 말하길 이 챕터를 여기에 넣는 것이 적절하지 않지만, 이론 설명 후에 구체적인 예시를 주고 싶어서 앞에 끼워넣었다고 합니다. 그런 이유로 이 챕터는 이전 챕터와 다음 챕터와는 직접적인 관련은 없습니다만, 추후에 이어지는 내용이 나오기 때문에 확실히 짚고 넘어가셔야 할 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;outline&quot;&gt;Outline&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-03.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번 챕터의 순서는 크게 입력값의 표현을 어떻게 할 것인지부터 시작해서 선형 분류(Linear Classification), 선형 회귀(Linear Regression)를 다루고 비선형 문제(Nonlinear)를 해결하기 위한 접근방법을 소개하며 끝나게 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;input-representation&quot;&gt;Input Representation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-04.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;간단한 예제로 사람이 손으로 쓴 숫자를 분류하는 문제를 들어봅시다. (우체국에서 손으로 쓴 주소를 기계가 분류하는 시스템을 구축한다고 생각하시면 이해가 쉬울 것 같습니다) 입력값은 위의 슬라이드에 나온 대로 사람들이 직접 손으로 쓴 숫자들을 따와서 사용하게 됩니다. 첫 번째 문제로, 입력 데이터는 그림인데, 기계학습으로 처리하기 위해서는 이를 수치화 시켜서 표현할 필요가 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-05.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림 데이터를 수치화시키는 방법은 여러가지가 있지만, 일반적으로 컴퓨터는 그림을 픽셀의 묶음으로 처리하기 때문에 그림의 각 픽셀값을 입력으로 변환하는 방법을 생각해볼 수 있습니다. 이 예제의 경우, 한 숫자 그림이 차지하는 픽셀이 256개라고 가정했습니다. ($x_0$는 Threshold를 위해 만든 Input입니다 - 챕터 1 참고)&lt;/p&gt;

&lt;p&gt;선형 분류의 대표적인 방법이 바로 챕터 1에서 소개되었던 Perceptron Learning Algorithm (PLA)입니다. 이 예제를 PLA로 푼다고 가정했을 때, Input Vector의 크기만큼 Weight Vector가 필요하니까 Weight Vector도 256+1 차원 만큼이 필요함을 알 수 있습니다. 물론 이렇게 놓고 문제를 풀 수도 있지만, 이런 간단한 문제에 이렇게 차원이 큰 벡터를 사용하기엔 비효율적입니다. 데이터를 256차원으로 표현한다고 해봤자 의미없는 입력값이 너무 많고 (예를 들면 귀퉁이부분의 픽셀) 하려고 하는 분류 난이도에 비해 구해야할 Weight의 갯수가 너무 많아 학습이 매우 느리게됩니다.&lt;/p&gt;

&lt;p&gt;그럼 이 데이터를 어떻게 간단하게 바꿀까요? 숫자의 모양을 이용한다면 0, 1, 8 같은 숫자는 대칭적이고 그 외의 숫자는 비대칭이니 대칭 여부를 통해 숫자를 1차적으로 분류하는 것도 문제를 간단하게 만드는 방법이 될 수 있습니다. 또한 1, 7에 비해서 8은 그림에서 차지하는 검은색 픽셀이 더 많습니다. 이것도 숫자를 분류하는 데 사용이 가능해 보입니다. 이 두가지 특징을 사용하여 Input Vector를 간단하게 2+1 차원으로 줄여봅시다.&lt;/p&gt;

&lt;h2 id=&quot;linear-classification&quot;&gt;Linear Classification&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-06.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Input Vector가 $x_0$, $x_1$, $x_2$ 단 3개로 줄어든 걸 볼 수 있습니다. $x_0$의 역할은 이전과 마찬가지로 Threshold 역할이고, $x_1$은 검은색 픽셀의 밀집도, $x_2$는 대칭 여부를 의미합니다. 간단하게 바꾼 Input Vector로 숫자 1과 5를 분류해 보았습니다. 아무래도 1보다 5가 차지하는 검은색 픽셀이 더 많고, 숫자 1은 대칭적인데 비해 5는 대칭적이지 않으니 이 둘을 구분하는건 크게 어렵지 않아 보입니다.&lt;/p&gt;

&lt;p&gt;다만 슬라이드의 그림을 자세히 보시면 대략적으로는 구분이 가능하지만, 몇몇 지점에서 약간의 Noise가 있음을 알 수 있습니다. 이 Noise 때문에 이 데이터는 &lt;strong&gt;선형 분리(Linearly Seperable)&lt;/strong&gt;가 불가능함을 알 수 있습니다. 챕터 1에서 PLA는 선형 분리가 불가능하면 수렴하지 않는다고 했기 때문에 이 문제 또한 학습 결과가 수렴하지 않습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-07.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;실제로 이전 슬라이드의 데이터를 사용하여 PLA를 수행한 결과입니다. 왼쪽 그림은 데이터의 갯수가 증가할수록 In Sample Error와 Out of Sample Error가 어떻게 변하는지를 나타내고 있습니다. 정상적인 학습이라면 데이터의 갯수가 증가할수록 두 Error 모두 0으로 수렴해야하지만, 이 문제에서는 데이터의 선형 분리가 불가능하니 수렴하지 않고 진동하는 모양의 그래프가 나옴을 알 수 있습니다. ($E_{in}$와 $E_{out}$의 변화를 참고하세요)&lt;/p&gt;

&lt;p&gt;여기서 눈치가 빠르신 분은 어떻게 정확한 $E_{out}$을 표현한 것인지 궁금하실텐데, 물론 실제로는 $E_{out}$를 알지 못하지만, 이 예제에서는 $E_{in}$와 $E_{out}$가 어떤 관계가 있는지 보여주기 위해서 전체 샘플을 제한하여 계산하였습니다.&lt;/p&gt;

&lt;p&gt;다행히도 이 문제에서는 $E_{in}$가 커지면 $E_{out}$도 커지고, 작아질 때도 같이 작아지는 비례 관계임을 알 수 있네요. (모든 문제가 그렇지는 않습니다. 이것은 아주 예외적인 경우입니다.) 즉, 앞으로는 $E_{in}$만 알아도 이를 낮추는 방향으로 설계를 한다면 $E_{out}$도 자연스레 줄어드는 결과가 나온다는 좋은 정보를 알게 되었습니다.&lt;/p&gt;

&lt;p&gt;그런데 왼쪽 그림을 보니 수행 횟수가 1000번일 때의 Error가 250번 정도일 때보다 크게 나타납니다. 하지만 이 알고리즘은 1000번 수행 후의 결과를 출력하다 보니 이전에 더 좋은 성능을 보이는 Weight Vector를 찾았음에도 그보다 못한 값이 최종 값으로 확정되어버렸네요. 이걸 개선한다면 이전보다 좋은(=Error가 낮은) Weight Vector를 찾을 수 있어 보입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-08.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서는 이 문제를 &lt;span style=&quot;color:red&quot;&gt;Pocket Algorithm&lt;/span&gt;으로 해결합니다. Pocket Algorithm은 수행 중에 최고 성능을 보이는 Weight Vector 값을 저장해 두고, Weight Vector가 변경되었을 시 성능이 기존보다 떨어진다면 이를 반영하지 않는 알고리즘입니다. (좋은 것을 찾았을 때 주머니에 넣어두는 것을 떠올리시면 이해가 편할 것 같습니다.) 즉, Pocket Algorithm을 사용한다면 Weight Vector를 학습시킬수록 Error가 높은 (낮은 성능을 보이는) Vector가 나온다고 해도 항상 최선의 결과만 출력해 줄 수 있다는 장점이 있습니다. 왼쪽 그림을 보시면 데이터의 수가 100~400개 근처일 때 가장 성능이 좋고, 이후에는 계속 이보다 나쁜 성능을 가지는 Vector만 나오다 보니 Pocket Algorithm의 경우 100 즈음부터 변화가 없는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-09.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 슬라이드는 PLA를 사용한 결과와 Pocket Algorithm을 사용한 결과를 비교한 그림입니다. 검은색 줄이 1로 판단할 것인가 5로 판단할 것인가를 나누는 기준선입니다. 선형 분리가 불가능하기 때문에 두 그림 모두 완벽하게 판별하지는 못하지만, 확실히 Pocket Algorithm으로 나눈 결과가 더 바람직해 보인다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;linear-regression&quot;&gt;Linear Regression&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-10.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;지금까지 선형 분류를 하는 방법을 알아보았습니다. 문제 난이도를 조금 올려, 이제 선형 회귀를 하는 방법을 알아보겠습니다. &lt;span style=&quot;color:red&quot;&gt;Regression&lt;/span&gt; (회귀)은 출력 결과가 +1/-1이 나오는 분류와는 다르게, 출력 결과로 실수값으로 나오는 것을 말합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-11.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;챕터 1에서 다루었던 카드를 발급하는 문제로 돌아와봅시다. 그때는 신청자의 정보를 바탕으로 카드를 발급해 줄 것인가/거부할 것인가의 여부를 다뤘다면, 이제는 카드 발급 여부에 더해 카드의 한도를 어떻게 정할 것인가를 구해야 합니다. 카드의 한도는 사람마다 다를 뿐더러 결과값이 실수(Real Number)로 나오기 때문에 이전보다 문제가 복잡해졌습니다. 지원자의 정보의 형태(Input Vector)는 분류를 할 때와 크게 다르지 않습니다만, 분류를 할 때와 달리 실수값의 출력이 나와야 하므로 Hypothesis $h$의 형태가 $sign()$ 함수를 떼버린 $\mathbf{w}^{\sf T} \mathbf{x}$ 꼴로 나오게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-12.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이전 슬라이드에서 언급했다시피 입력 값은 분류때와 큰 차이점은 없습니다.
다만 분류에서는 $y_n$의 값이 +1/-1이었지만 회귀에서는 실수 값이 들어간다는 것만 주의하시면 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-13.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;문제가 다르니 Error를 어떻게 측정할 것인가도 생각해 보아야합니다. 분류에서는 출력이 +1/-1 뿐이다 보니 그냥 정답과 다른 것의 갯수만 세면 충분했습니다. 그래서 전체 중에 몇개나 틀렸는지를 비율로 표시하였습니다.&lt;/p&gt;

&lt;p&gt;하지만 회귀에서는 출력의 값이 무한정 많다보니 단순히 틀렸냐 틀리지 않았냐만을 따지기에는 곤란합니다. 예를 들어 정답 출력이 1000 인 입력값에 대해서, 950 정도 예측한 것과 5000으로 예측한 것은 둘다 틀린 결과값이지만 똑같이 오답으로 처리하기에는 무리가 있습니다. 950정도면 틀려도 감수할만한 값일 수 있지만, 5000은 도저히 용납이 불가능하기 때문입니다. 따라서 각 입력값에 대해 얼마나 “큰 차이”로 틀렸냐를 토대로 Error를 측정하게 됩니다. 이 “차이”를 측정하는 방법은 여러 가지가 있지만, 이 강의에서는 Hypothesis Function과 Target Function의 차이를 제곱한 값을 사용하게 됩니다.이를 &lt;span style=&quot;color:red&quot;&gt;Squared Error&lt;/span&gt;라고 합니다.&lt;/p&gt;

&lt;p&gt;이걸 보시면 “단순한 차이를 원한다면 제곱할 필요 없이 그냥 차이의 절대값을 쓰면 되는게 아닌가?” 라는 의문이 드실 수도 있습니다. 제곱을 쓰는 데는 여러가지 이유가 있으나 대표적인 이유로는 절대값을 쓰게 되면 미분이 힘들어지기 때문입니다. 차이가 크면 클수록 패널티를 많이 주기 위함도 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-14.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 Error Measure를 그림으로 표현한 슬라이드 입니다. 왼쪽 그림은 Input Vector가 1차원일 때의 예시이며, 오른쪽 그림은 Input Vector가 2차원일 때의 예시입니다. 파란색 선(오른쪽 그림에서는 파란색 평면)이 의미하는 것은 Hypothesis Function $h$이고, 빨간색 선이 실제 분류값(Target Fucntion $f$의 값)과 예측한 결과 값의 차이입니다. 헷갈리실수도 있지만, 빨간색 선을 그릴 때 $h$에 대해서 직교하는 선을 그리는 것이 아님을 유의하셔야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-15.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 이 Error Measure를 통해서 $E_{in}$을 계산해봅시다. 입력값의 개수가 $N$이므로 모든 입력값에 대해 평균적인 차이를 계산한다면 아래와 같습니다.&lt;/p&gt;

\[E_{in}(\mathbf{w}) = \frac{1}{N} \sum_{n=1}^N (\mathbf{w}^{\sf T} \mathbf{x}_n - y_n)^2\]

&lt;p&gt;식을 좀 더 간단하게 표현하기 위하여, $\mathbf{x}_n$들을 묶어 $\mathbf{X}$라는 큰 벡터로 표현해봅시다. 그리고 출력값인 $y_n$도 하나로 묶어 $\mathbf{y}$로 묶어보겠습니다. 이렇게 바꾸면 $\Sigma$(Sigma) 연산이 사라지고, $\mathbf{X}$ 벡터와 $\mathbf{w}$ 벡터의 곱 연산으로 간단하게 나타낼 수 있습니다. 따라서 아래와 같이 간단한 꼴로 표현이 됩니다.&lt;/p&gt;

\[E_{in}(\mathbf{w}) = \frac{1}{N} \lVert \mathbf{X}\mathbf{w} - \mathbf{y} \rVert^2\]

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-16.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;최종적으로 구하고자 하는 것은 $E_{in}$의 최소값입니다. 어떤 함수의 어디에서 최소값을 갖는지 구하는 방법은 그 함수의 도함수(Derivative)를 구해서 그 값이 0인 점을 찾으면 됩니다. (물론 모든 함수의 최소값이 도함수가 0인 점이라는 것은 아닙니다만, $E_{in}$ 함수는 볼록 함수(Convex Function)이므로 최소값입니다) $E_{in}$을 미분하려면 Vector Calculus를 알아야 하는데, 모르시는 분을 위해서 중간 과정을 조금 적어드리겠습니다. (저도 Vector Calculus를 제대로 배워본적이 없어서 틀린 부분이 있다면 댓글로 지적 부탁드립니다)&lt;/p&gt;

\[E_{in}(\mathbf{w}) = \frac{1}{N} \lVert \mathbf{X}\mathbf{w} - \mathbf{y} \rVert^2\]

&lt;p&gt;위의 원래의 식에서 제곱을 없애기 위해 $\lVert \cdot \rVert$ 부분을 풀어 써 보겠습니다.&lt;/p&gt;

\[E_{in}(\mathbf{w}) = \frac{1}{N} (\mathbf{X}\mathbf{w} - \mathbf{y})^{\sf T} (\mathbf{X}\mathbf{w} - \mathbf{y})\]

&lt;p&gt;위 식에서 전치행렬(Transpose Matrix) 기호 $\sf T$가 어디서 튀어나왔나 싶으실텐데 이것은 $\sf T$를 붙이지 않으면 행렬 곱을 할 수 없기 때문에 벡터 계산 중 붙여진 것이라고 생각하시면 됩니다.&lt;/p&gt;

&lt;p&gt;()위에 붙어있는 $\sf T$가 보기 싫으니, $\sf T$를 () 안으로 넣어줍시다.&lt;/p&gt;

\[E_{in}(\mathbf{w}) = \frac{1}{N} (\mathbf{w}^{\sf T} \mathbf{X}^{\sf T} - \mathbf{y}^{\sf T}) (\mathbf{X}\mathbf{w} - \mathbf{y})\]

&lt;p&gt;이 식을 전개한다면,&lt;/p&gt;

\[E_{in}(\mathbf{w}) = \frac{1}{N} (\mathbf{w}^{\sf T} \mathbf{X}^{\sf T} \mathbf{X} \mathbf{w} - 2 \mathbf{y}^{\sf T} \mathbf{X} \mathbf{w})\]

&lt;p&gt;이렇게 쓸 수 있습니다. $E_{in}$은 $\mathbf{w}$에 대한 함수이므로 $\mathbf{w}$로 미분을 하게 되면($\nabla E_{in}(\mathbf{w})$) 아래와 같이 도함수가 0이 되는 $\mathbf{w}$를 찾는 문제로 바뀌게 됩니다.&lt;/p&gt;

\[\frac{2}{N} \mathbf{X}^{\sf T} (\mathbf{X}\mathbf{w} - \mathbf{y}) = 0\]

&lt;p&gt;여기서 $\frac{2}{N}$은 의미없는 상수이므로 지워주게 되면,&lt;/p&gt;

\[\mathbf{X}^{\sf T} (\mathbf{X}\mathbf{w} - \mathbf{y}) = 0\]

&lt;p&gt;괄호 ()를 없애기 위해 분배법칙을 사용해 전개해줍니다.&lt;/p&gt;

\[\mathbf{X}^{\sf T}\mathbf{X}\mathbf{w} - \mathbf{X}^{\sf T}\mathbf{y} = 0\]

&lt;p&gt;$\mathbf{X}^{\sf T}\mathbf{y}$항을 오른쪽으로 넘겨주면,&lt;/p&gt;

\[\mathbf{X}^{\sf T}\mathbf{X}\mathbf{w} = \mathbf{X}^{\sf T}\mathbf{y}\]

&lt;p&gt;왼쪽 항에 $\mathbf{w}$만 남기기 위해서는 $\mathbf{X}^{\sf T}\mathbf{X}$의 역행렬을 양쪽에 곱해주어야 합니다. 일단 $\mathbf{X}$ 자체는 정사각행렬(Square Matrix)이라는 보장이 없지만, 임의의 행렬에 대해서 그 행렬의 전치행렬을 곱해주면 정사각행렬이 되므로 $\mathbf{X}^{\sf T}\mathbf{X}$는 정사각행렬입니다. (임의의 행렬이 크기가 $n \times m$ 이라 했을 때, 이 행렬의 전치행렬은 $m \times n$이 되고, ($m \times n$ 행렬)($n \times m$ 행렬) 연산을 해주면 $m \times m$ 행렬이 나오므로 $m$과 $n$에 관계없이 무조건 정사각행렬이 됩니다)&lt;/p&gt;

&lt;p&gt;이제 $\mathbf{X}^{\sf T}\mathbf{X}$ 행렬이 역행렬이 존재하는지 확인해야 하는데, 만약에 이 행렬의 역행렬이 존재하지 않는다면 위의 식 자체가 의미가 없어져 버리므로, 여기서는 있다고 가정하고 계산하겠습니다.&lt;/p&gt;

&lt;p&gt;양쪽 항에 $\mathbf{X}^{\sf T}\mathbf{X}$의 역행렬을 곱해주면,&lt;/p&gt;

\[\mathbf{w} = (\mathbf{X}^{\sf T}\mathbf{X})^{-1}\mathbf{X}^{\sf T}\mathbf{y}\]

&lt;p&gt;이 성립하게 됩니다. 여기서 $\mathbf{X}$와 관련된 항인 $(\mathbf{X}^{\sf T}\mathbf{X})^{-1}\mathbf{X}^{\sf T}$를 묶어서 $\mathbf{X}^{\dagger}$이라 한다면 아래처럼 깔끔하게 바뀌게 됩니다. $\dagger$ 기호는 대거(Dagger)라고 읽으시면 됩니다.&lt;/p&gt;

\[\mathbf{w} = \mathbf{X}^{\dagger}\mathbf{y}\]

&lt;p&gt;여기서 $\mathbf{X}^{\dagger}$를 $\mathbf{X}$의 &lt;span style=&quot;color:red&quot;&gt;Pseudo-Inverse&lt;/span&gt; (의사역행렬)라고 합니다. 이런 이름이 붙은 이유는, 이 행렬은 $\mathbf{X}$의 역행렬이 아님에도 불구하고 역행렬처럼 $\mathbf{X}^{\dagger}\mathbf{X} = I$가 나오는 성질을 가지기 때문입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-17.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이전 슬라이드에 수식이 너무 많아 당황하셨을 수도 있지만, 걱정하지 않으셔도 됩니다. Pseudo-Inverse의 전개 과정을 안다면 더욱 좋겠지만 모르셔도 전체적인 이론을 이해하는데는 큰 무리가 없습니다. “회귀 문제를 풀기 위해서는 Pseudo-Inverse를 계산해야 하는구나” 정도만 아시면 됩니다. 어차피 요즘엔 MATLAB 등과 같은 수학 관련 프로그램이 모두 계산해주기 때문입니다.&lt;/p&gt;

&lt;p&gt;이번에는 Pseudo-Inverse 행렬이 어떤 크기를 갖는지 알아봅시다. $\mathbf{X}$는 $d$차원의 입력이 $N$개 만큼 있으니 $N \times (d+1)$ 크기의 행렬이 될 것입니다. ($d$ 가 아니라 $d+1$ 인 이유는 Threshold를 나타내는 $x_0$가 포함되기 때문입니다) 그럼 $\mathbf{X}^{\sf T}$는 반대로 $(d+1) \times N$ 크기의 행렬이니 $\mathbf{X}^{\sf T} \mathbf{X}$ 를 계산한다면 $(d+1) \times (d+1)$ 크기의 행렬이 됨을 알 수 있습니다. 역행렬을 구한다고 해도 행렬의 크기는 변하지 않으니 $(\mathbf{X}^{\sf T} \mathbf{X})^{-1}$ 또한 $(d+1) \times (d+1)$ 크기의 행렬이 됩니다. $\mathbf{X}^{\sf T}$행렬은 $(d+1) \times N$ 크기라고 했으니 $(\mathbf{X}^{\sf T} \mathbf{X})^{-1} \mathbf{X}^{\sf T}$를 계산하면 최종적으로 Pseudo-Inverse $\mathbf{X}^{\dagger}$는 $(d+1) \times N$ 크기의 행렬이 된다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-18.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;최종적으로 선형 회귀를 하는 알고리즘을 정리해보면, 첫째로 입력값과 그 정답을 나타내는 값을 각각 $\mathbf{X}$와 $\mathbf{y}$ 행렬로 묶어주고, 둘째로 Pseudo-Inverse $\mathbf{X}^{\dagger}$를 계산한다음, 마지막으로 Pseudo-Inverse $\mathbf{X}^{\dagger}$와 $\mathbf{y}$를 곱해주면 $\mathbf{w}$를 알 수 있게 됩니다.&lt;/p&gt;

&lt;p&gt;이 과정을 보시면 한번만 계산하면 끝나기 때문에 Learning이 아니라고 생각하실 수도 있습니다. 다만 책의 저자이신 Abu-Mostafa 교수님께서는 꼭 PLA처럼 모든 데이터에 대해 하나하나 Weight Vector를 수정하는 것만이 Learning이 아니라고 합니다. 다시 말해서 어떻게 구하는지 그 과정은 별로 중요한 것이 아니라고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-19.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;선형 회귀는 결과 값이 실수로 나온다는 것을 알고 있습니다. 그런데 선형 분류에서 나오는 결과는 +1/-1인데, 이것도 실수니까 회귀와 연관을 지을 수 있지 않을까 하는 생각을 해봅니다. 선형 회귀를 조금 응용한다면 Weight Vector $\mathbf{w}$를 가지고 선형 분류를 할 수 있지 않을까라는 겁니다.&lt;/p&gt;

&lt;p&gt;안타깝게도 회귀와 분류는 그 목적이 다르기 때문에 그대로 사용할 수는 없습니다. 하지만 회귀에 사용한 데이터를 이용해 분류에 도움을 줄 수는 있습니다. 기존에 분류를 할 때 $\mathbf{w}$의 초기값을 무작위 값(혹은 0벡터)으로 정의하였지만, 회귀에서 사용했던 $\mathbf{w}$를 초기값으로 정하게 된다면 분류에 수렴하기까지 시간이 매우 단축되는 결과를 얻을 수 있다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-20.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;선형 회귀에서 구한 Weight Vector $\mathbf{w}$를 초기값으로 설정해 선형 분류 문제의 그림으로 표현한 결과입니다. 완벽하지는 않지만, 정답과 매우 유사한 분류가 이루어졌음을 알 수 있습니다. 이 상태에서 시작해 PLA 등의 선형 분류 알고리즘을 수행한다면, 많은 단계를 거치지 않아도 최적의 $\mathbf{w}$을 쉽게 구할 수 있겠구나라는 것을 예상할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;nonlinear-transformation&quot;&gt;Nonlinear Transformation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-21.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 마지막으로 비선형(Non-Linear) 문제는 어떻게 해결하는지를 알아봅시다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-22.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;선형 분류/회귀는 굉장히 편리하고 효과가 좋은 방법이지만, 안타깝게도 모든 문제가 선형으로 해결되지는 않습니다. 간단한 예제로 위 슬라이드의 왼쪽 그림과 같은 데이터의 경우, 어떻게 나누어도 직선으로는 분류할 수 없습니다. 오른쪽 그림처럼 원 모양으로 표현해야 제대로 나누어질텐데, 선형 방법으로는 저렇게 원 형태를 표현할 수 없는 것이 문제입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-23.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;잠시 카드 발급 문제로 돌아가서 “years in residence” 라는 요소를 생각해봅시다. 왜 그런지는 모르겠지만, 한 집에서 너무 적게 거주했거나(1년 미만) 너무 오래 거주한 경우(5년 초과) 부정적으로 평가한다고 합니다. 이런 경우 선형 모델을 통해 표현할 수 있을까요?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-24.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 문제에 답을 하기 위해서는 &lt;strong&gt;“무엇”&lt;/strong&gt;에 대해 선형이냐 라는 것부터 생각해보아야 합니다. 입력 값이 선형이기 때문에 선형 모델이라고 생각하시는 분들이 있는데, 선형 모델이라고 이름이 붙은 이유는 “Weight”에 대해 선형이기 때문에 선형 모델이라고 부르는 겁니다. 그러니까, 다시 말해서 입력값 $\mathbf{x}$은 선형이든 아니든 크게 상관이 없다는 겁니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/3. Linear Models I/ML 03-25.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 입력값이 선형일 필요는 없다고 했으니, 입력 값을 한번 바꾸어봅시다. 임의의 함수 $\Phi$를 정의해서 입력값 $\mathbf{x}$ 제곱하는 연산을 수행하게 만들어 봅시다. 위 슬라이드의 왼쪽 그림은 20번 슬라이드에 나왔던 그 예제입니다. 그런데 모든 데이터에 대해 $\Phi$ 함수를 거친 결과값을 표현하니 오른쪽 그림처럼 변했습니다. 이 바뀐 데이터의 분포는 선형 분리까지 가능해 보인다는 것을 쉽게 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;이런 방법을 통해 선형 분리가 도저히 안되는 데이터의 경우 임의의 함수를 정의하여 데이터를 변환시킴으로써 선형 분류가 가능하지만, 여기에는 한 가지 문제가 있습니다. 위의 그림처럼 간단한 예제의 경우에는 적당한 함수 $\Phi$를 쉽게 구했지만, 일반적인 상황에서는 적절한 $\Phi$를 찾는 것이 쉽지 않습니다. 그렇기에 또다른 방법이 필요하지만, 이 문제에 대한 해결 방법은 추후에 다시 언급됩니다.&lt;/p&gt;

&lt;p&gt;이번 챕터는 여기까지입니다. 읽어주셔서 감사합니다.&lt;/p&gt;</content><author><name>Joonsu Ryu</name></author><category term="studies" /><category term="machine learning" /><summary type="html"></summary></entry><entry><title type="html">Is Learning Feasible?</title><link href="http://localhost:4000/studies/is-learning-feasible/" rel="alternate" type="text/html" title="Is Learning Feasible?" /><published>2019-07-25T00:00:00+09:00</published><updated>2019-07-25T00:00:00+09:00</updated><id>http://localhost:4000/studies/is-learning-feasible</id><content type="html" xml:base="http://localhost:4000/studies/is-learning-feasible/">&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-02.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;두 번째 챕터는 지난번 챕터의 마지막 이슈였던 “학습은 가능한 것인가?” 라는 의문을 해결하는 강의입니다.&lt;/p&gt;

&lt;h2 id=&quot;outline&quot;&gt;Outline&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-03.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번 챕터는 총 4부분으로 구성되어 있습니다. 먼저 확률론적으로 예제를 통해 접근하고, 이를 기계학습과 연결하는 과정을 거칩니다. 하지만 이 과정에서 몇 가지의 문제가 생기는데, 이 원인과 그 해결책은 무엇인지까지 다루게 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;probability-to-the-rescue&quot;&gt;Probability to the rescue&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-04.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;가장 먼저, 위 슬라이드의 오른쪽 그림과 같이 빨간색 구슬과 초록색 구슬이 들어있는 통(Bin)을 생각해 봅시다. 이 통에서 무작위로 구슬을 하나 뽑았을 때, 그 구슬이 빨간색일 확률을 $\mu$라고 한다면 자연스럽게 초록색 구슬을 뽑을 확률은 $1-\mu$이 됩니다. 그런데 문제는, 우리는 이 통에 빨간색 구슬이 얼마나 들었는지 모르기 때문에 정확한 $\mu$은 모르는 상태입니다. 그래서 이를 확인하기 위해, 이 통에서 무작위로 $N$개의 구슬을 뽑기로 했습니다. 뽑은 $N$개의 구슬에서 빨간색 구슬의 비율을 $\nu$라고 정의합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-05.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그렇다면 $\nu$를 가지고 $\mu$를 알 수 있을까요? 상황에 따라서 그렇다고 볼 수도 있고, 아닐 수도 있습니다.&lt;/p&gt;

&lt;p&gt;먼저, 할 수 없다고 말할 수 있는 이유는 $\nu$는 통에서 일부분만을 꺼낸 구슬이기 때문에, 통에 들어있는 구슬의 비율과 다르게 나올 가능성이 존재합니다. 예를 들어, 통에 빨간색 구슬이 90개, 초록색 구슬이 10개가 들어있다고 가정해봅시다. 이 통에서 무작위로 10개의 구슬을 뽑았을 때, 정말 낮은 확률로 초록색 구슬만 10개가 나올 수도 있습니다. 따라서 이러한 경우엔 $\nu$가 $\mu$와 같다고 말할 수 없습니다. 하지만 만약 한번에 뽑는 구슬의 수가 많아진다면 (다시말해 $N$이 커진다면) $\nu$가 $\mu$와 같지는 않더라고 점점 가까워짐을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;유튜브 강의에서는 이를 가지고 &lt;strong&gt;Possible&lt;/strong&gt; vs &lt;strong&gt;Probable&lt;/strong&gt; 이라 설명합니다. 아마 Possible이라는 것은 $\nu$와 $\mu$가 다를 수 있다는 예제를 말하는 것 같고 Probable이라는 것은 $N$이 커졌을 때 $\nu$와 $\mu$가 가까워 진다는 것을 말하는 것으로 해석됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-06.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이전 슬라이드 마지막에서 말했던 것처럼 $N$이 커졌을 때 $\nu$와 $\mu$이 가까워질 수 있다는 것을 알았습니다. 이를 수학적으로 표현한다면 슬라이드에 나와있는 부등식처럼 표현할 수 있습니다. 이를 &lt;span style=&quot;color:red&quot;&gt;Hoeffding’s Inequality&lt;/span&gt;라고 부릅니다.&lt;/p&gt;

&lt;p&gt;이 부등식이 무엇을 의미하는지 하나씩 따져봅시다. 먼저 $| \nu - \mu |$라는 것은 &lt;strong&gt;샘플로 뽑은 $N$개의 구슬에서 빨간색 구슬의 비율과 실제 통에 들어있는 구슬에서 빨간색 구슬의 비율&lt;/strong&gt;의 차이를 의미합니다. 궁극적으로 우리가 원하는 것은 이 둘이 차이가 거의 없는 것이기 때문에 $| \nu - \mu | &amp;gt; \epsilon$의 의미는 우리가 원하지 않는 상황(유튜브 강의에서는 Bad Event로 지칭합니다)으로 볼 수 있습니다. 따라서 왼쪽 항이 의미하는 것은 우리가 원하지 않는 상황(즉, $\nu$와 $\mu$의 차이가 일정 이상 벌어지는 상황)이 일어날 확률을 의미하는 것이 됩니다.&lt;/p&gt;

&lt;p&gt;이번엔 오른쪽 항을 분석해 봅시다. 왼쪽 항이 “확률”을 의미하는 식이었으니 당연히 오른쪽 항은 0과 1 사이의 값이 나와야 합니다. 오른쪽 항은 $\epsilon$과 $N$에 영향을 받는 지수함수이니 이 두 변수에 어떤 값이 들어오는지에 따라 결정됨을 쉽게 알 수 있습니다. 간단하게 표현하면, $\epsilon$과 $N$의 값이 크면 클수록 오른쪽 항의 값이 작아집니다.&lt;/p&gt;

&lt;p&gt;이렇게 Hoeffding’s Inequality로 표현한 것을 다른 말로 하면 “$\mu = \nu$”는 P.A.C (Probably Approximate Correct)라 합니다. 쉽게 말하면 &lt;strong&gt;“아마 대략적으로 맞다”&lt;/strong&gt; 라는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-07.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이전 슬라이드에서 설명했던 Hoeffding’s Inequality는 모든 $\epsilon$과 $N$에 대해 성립하고, 마침 오른쪽 항은 $\mu$ 에도 영향을 받지 않으니 부등식이 매우 간단해졌습니다. 왜냐하면 $\mu$는 우리가 모르는 값이기 때문에 이게 오른쪽 항에도 있었다면 계산이 상당히 껄끄러웠을 겁니다.&lt;/p&gt;

&lt;p&gt;다만 이 부등식이 의미있는 식이 되기 위해서는 오른쪽 항이 0과 1 사이의 값이 되어야 하는데, 이 문제가 조금 복잡합니다. 지수함수 $e^{-2 \epsilon ^{2} N}$의 계수가 2이므로 이 지수함수 $e^{-2 \epsilon ^{2} N}$의 값은 0.5보다 작아야 오른쪽 항이 1보다 작을 수 있습니다. 그런데 이 지수함수 $e^{-2 \epsilon ^{2} N}$의 값이 0.5보다 작아지려면 가급적 지수부분 $2 \epsilon ^{2} N$이 커야 함을 알 수 있습니다. 그런데 여기서 문제가 생기는 것이, $\epsilon$은 $| \nu - \mu |$와 관련이 있으므로 최대한 작게 잡아야합니다. 보통 매우 작은 소수 (예를 들면 0.001)로 정하는데 이걸 제곱까지 해주기 때문에 $N$의 값이 매우매우매우 커야 한다는걸 의미합니다. 다만 여기서는 일단 이 문제는 제쳐놓고, “$\nu$와 $\mu$의 값이 유사해진다”라는 결론만을 짚고 넘어가겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;connection-to-learning&quot;&gt;Connection to learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-08.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 지금까지 이야기했던 구슬 문제를 기계학습에 적용시켜 보겠습니다. 통 안에 들어있는 구슬들은 모든 데이터라고 가정해봅시다. (이전 챕터에서 얘기했던 카드 발급 문제를 예시로 들자면, 카드를 발급하러 신청한 모든 사람들이 통 속의 구슬이 됩니다.) 그리고 통 안에 들어있는 구슬중에 초록색 구슬은 Hypothesis $h$가 정확하게 분류한 데이터(즉, $h(x) = f(x)$), 빨간색 구슬은 Hypothesis $h$가 잘못 분류한 데이터(즉, $h(x) \neq f(x)$)라고 합시다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-09.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이전 챕터에서 얘기했던 그림이 또 나왔습니다. 이 때에는 Traning Examples들이 우리가 모르는 Target Function $f$으로부터 생성된 데이터라고 했지만, 지금까지 기계학습 문제를 확률적인 얘기로 예시를 들었으니, 이 Traning Examples들의 데이터 $x_1, x_2, …, x_N$들이 어떠한 확률 분포(이 확률 분포가 무엇인지는 중요하지 않습니다)를 따른다고 가정한다면 앞부분에서 설명한 구슬 문제에 완벽하게 매칭이 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;connection-to-real-learning&quot;&gt;Connection to real learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-10.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 이제 끝난 것일까요? 아쉽게도 그렇지 않습니다. 왜냐면 지금까지 비유를 든 예제는 오로지 특정한 ‘단 하나’의 Hypothesis인 $h$에 대해서만을 가정했기 때문입니다. 이전 챕터에서 Hypothesis는 한개가 아니라 set이 존재한다고 했었기 때문에 지금까지 다루었던 가정들을 다른 모든 Hypothesis에 대해서도 마찬가지고 적용해야 합니다. 사족으로, 이렇게 단 하나의 Hypothesis $h$만을 다룬 것은 학습(Learning)이 아니라 검증(Verification)이라고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-11.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;따라서 이를 일반화하기 위해서는, 위 슬라이드의 그림과 같이 많은 통들을 생각해 보아야 합니다. 구슬(데이터)이 빨간색일지 초록색일지는 Hypothesis들에 따라 다르기 때문에 각각의 통에서 뽑아낸 샘플에서의 빨간색 구슬의 비율(=$\nu$)은 각자 다르다는 것을 알 수 있습니다. 이 문제를 쉽게 다루기 위해, 통의 개수는 $M$개로 유한하다고 가정하겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-12.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 구슬의 예제에서 벗어나 완벽하게 학습 문제에 적용시키이 위해, 용어를 좀 바꾸어 보겠습니다. 우리가 직접 뽑은 구슬에서의 빨간색 구슬의 비율 $\nu$를 학습 문제에 매칭시킨다면, Hypothesis $h$가 잘못 분류한 데이터(즉, $h(x) \neq f(x)$)를 의미합니다. 이를 $E_{in} (h)$ (&lt;span style=&quot;color:red&quot;&gt;In Sample Error&lt;/span&gt;)라고 합니다. 마찬가지로 통 안에 들어있는 전체 구슬 중에 빨간색 구슬의 비율 $\mu$를 학습 문제에 매칭시킨다면, 이를 $E_{out} (h)$ (&lt;span style=&quot;color:red&quot;&gt;Out of Sample Error&lt;/span&gt;)라고 합니다.&lt;/p&gt;

&lt;p&gt;앞으로는 $\nu$와 $\mu$ 기호 대신 $E_{in} (h)$, $E_{out} (h)$를 쭉 사용하게 되니 이 정의를 잘 기억하고 계셔야 합니다. 위 슬라이드 마지막에는 앞에서 설명한 Hoeffding’s Inequality에서 $\nu$와 $\mu$ 기호 대신 $E_{in} (h)$, $E_{out} (h)$를 사용한 식으로 바꾸어 표현하였습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-13.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;앞의 여러개의 통을 사용한 예시를 $E_{in} (h)$, $E_{out} (h)$를 사용한 표현으로 바꾼 것을 보여주는 슬라이드입니다.&lt;/p&gt;

&lt;h2 id=&quot;a-dilemma-and-a-solution&quot;&gt;A dilemma and a solution&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-14.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;자 그럼 모든 Hypothesis에서 적용되게 만든 것으로 바꾼 것으로 문제가 해결되었을까요? 아니, 근데 더 큰 문제가 생겼습니다. 하나의 Hypothesis 가정을 전체의 Hypothesis 가정으로 바꿨더니 이제는 Hoeffding’s Inequality가 적용되지 않는 문제가 발생했습니다!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-15.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;왜 Hoeffding’s Inequality가 적용되지 않는지 동전 던지기 예제를 통해 알아봅시다. 만약에 공평한 동전(던졌을 때 앞이 나올 확률과 뒤가 나올 확률이 같은 동전) 한개를 10번 던졌을 때 10번 전부 앞면이 나올 확률은 0.1% 정도 됩니다. 그런데 1000개의 동전을 10번 던졌을 때 10번 전부 앞면이 나오는 동전이 1개 이상 있을 확률이 63%나 됨을 알 수 있습니다. 아까 구슬의 들어있는 통들과 연결이 되시나요?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-16.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 예제에서 동전을 우리가 생각했던 Hypothesis(=구슬이 들어있는 통)로 매칭시킨다면 여러개의 Hypothesis를 사용했을 때에도 확률이 더해짐을 알 수 있습니다. 조금 더 세부적으로, 우리가 직접 확인하는 Sample data (In Sample)도 전체 중에서 무작위로 뽑히므로, 이 중에는 정말 운이 좋게도 모든 Sample이 Hypothesis에 들어맞는 경우(즉, $E_{in} (h) = 0$)도 나올 수 있습니다. 그럼 이게 바로 정답일까요? 하지만 슬프게도 당연히 아니겠죠. 이건 정말 운좋게 Sample이 이렇게 나온 것일 뿐이니까요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-17.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이전의 우리의 문제는 여러개의 Hypothesis를 사용했을 때 Hoeffding’s Inequality가 적용되지 않는 것이였으므로, 방금 전의 동전 예제를 이용해 적용이 되게끔 식을 바꾸어봅시다. 눈썰미가 좋으신 분이면 위 슬라이드 식의 좌항이 $h$에 대한 In Sample/Out of Sample Error가 아니라 $g$에 관한 In Sample/Out of Sample Error로 바뀌었다는 것을 눈치채셨을 겁니다. 여기서의 $g$는 이전 챕터에서 언급했듯이 Hypothesis set에서 가장 성능이 좋은 Hypothesis를 의미하는 겁니다. 성능이 가장 좋다는 뜻은, ($g$에서 In Sample Error와 Out of Sample Error의 차이가 $\epsilon$보다 클 확률)이 다른 모든 Hypothesis와 비교해 보았을 때, (임의의 $h$에서 In Sample Error와 Out of Sample Error의 차이가 $\epsilon$보다 클 확률) 이하라는 의미입니다.&lt;/p&gt;

&lt;p&gt;오른쪽 항에서는 각각의 Hypothesis에 대해서 각각 Hoeffding’s Inequality가 적용되므로, 간단하게 이를 합친다면 각각 Hypothesis에서 발생하는 Hoeffding’s Inequality를 더한 값으로 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/2. Is Learning Feasible/ML 02-18.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과적으로 $g$에서의 Hoeffding’s Inequality는 기존의 Hoeffding’s Inequality 좌항에 Hypothesis의 개수인 $M$을 곱한 값이 되었습니다. 이 식은 겉으로 보기엔 아무 문제가 없지만, 오른쪽 항의 $M$이 아주 큰 문제를 야기할 수 있습니다. 아까도 설명드렸다시피 오른쪽 항이 의미가 있으려면 0과 1 사이의 값으로 나와야 하는데, 만약 Hypothesis의 개수(=$M$)가 엄청나게 많다면 1보다 작다는 것을 보장할 수 업습니다. 오른쪽 항이 1보다 크게 된다면 결과적으로 이 식은 아무런 의미를 가질 수가 없습니다. 불행하게도, 일반적인 문제에서 Hypothesis의 개수는 매우 많습니다. 이 부등식을 의미있게 하기 위해서는 좀 더 tight한 범위로 잡을 필요가 있습니다. 궁금하시겠지만, 이 이야기는 챕터 5에서 이어지게 됩니다.&lt;/p&gt;

&lt;p&gt;이번 챕터는 여기까지입니다. 읽어주셔서 감사합니다.&lt;/p&gt;</content><author><name>Joonsu Ryu</name></author><category term="studies" /><category term="machine learning" /><summary type="html"></summary></entry><entry><title type="html">The Learning Problem</title><link href="http://localhost:4000/studies/the-learning-problem/" rel="alternate" type="text/html" title="The Learning Problem" /><published>2019-07-17T00:00:00+09:00</published><updated>2019-07-17T00:00:00+09:00</updated><id>http://localhost:4000/studies/the-learning-problem</id><content type="html" xml:base="http://localhost:4000/studies/the-learning-problem/">&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-02.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;첫 번째 챕터는 어떤 것이 Learning Problem인가에 대해 설명하는 강의입니다.&lt;/p&gt;

&lt;p&gt;타이틀 슬라이드의 오른쪽 아래를 보시면 무언가 기하학적인 모양이 나와있는 그림이 있는데, 저번 글과 비교해 보시면 교재 표지에 똑같은 그림이 나와있다는 것을 알 수 있습니다. 이 그림은 추후 중요한 챕터에서 나올 그림이니 기억해 두시길 바랍니다. 나중에 이 그림이 다시 나왔을 때 또 언급하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;outline&quot;&gt;Outline&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-03.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이번 챕터의 구성은 총 다섯 부분으로 나뉘어 있습니다. 첫째로 기계학습의 예시를 보여주고, 둘째로 기계학습의 구성 요소를 설명합니다. 셋째로 간단한 예시 모델을 설명하며, 넷째로 기계학습의 종류를 설명합니다. 마지막으로 간단한 퍼즐을 통해 이번 챕터에서 배운 내용을 점검하게 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;example-of-machine-learning&quot;&gt;Example of Machine Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-04.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;먼저 간단한 기계 학습의 예시를 들면서 시작하겠습니다.&lt;/p&gt;

&lt;p&gt;만약 관객이 영화를 관람한 후, 그 영화에 평점을 몇 점 매길 것인가 예측하는 문제가 있다고 가정해봅시다. 넷플릭스 같이 영화를 판매하는 회사들은 해당 유저가 높은 평점을 매길 영화(즉, 좋아할 만한)를 예측하여 유저에게 추천하는 기능이 있습니다. 당연히 예측의 정확도가 높을 수록 그 회사의 수익이 증가하게 되므로, 이 정확도를 높일 수 있는 방법을 꾸준히 연구하고 있습니다. 강의에서 언급하길, 실제로 넷플릭스의 추천 기능을 10% 향상을 시키는 사람에게 백만달러의 상금을 걸었다고 합니다.&lt;/p&gt;

&lt;p&gt;이런 문제를 기계학습으로 해결 할 수 있을까요?&lt;/p&gt;

&lt;p&gt;주어진 문제를 기계학습으로 해결하기 위해서는 다음 3가지 조건이 반드시 필요합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;패턴이 존재해야 한다.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;이를 수학적으로 나타낼 수 없어야 한다. (예를 들면 정확한 함수)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;데이터를 가지고 있어야 한다.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;span style=&quot;color:red&quot;&gt;1번 조건&lt;/span&gt;부터 하나씩 따져봅시다. 만약 데이터에 패턴이 존재하지 않고 결과값이 무작위로 나온다면 해당 문제는 기계학습으로 풀 수 없습니다. 하지만 영화 추천 문제의 경우, 사람마다 선호하는 영화의 스타일이 존재하므로 패턴이 존재한다고 말할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:red&quot;&gt;2번 조건&lt;/span&gt;은 조금 이상하게 느껴질 수도 있습니다. 이 말은 만약 사람을 입력으로 넣고, 그 사람의 취향이 완벽히 반영되어 어떤 영화를 선호하는지 결과값으로 출력할 수 있는 함수를 구할 수 있으면 안된다는 것입니다. 만약 구할 수 있다면, 그것을 그냥 계산하면 되므로 굳이 기계학습을 쓸 필요가 없습니다. 위에서 언급한 넷플릭스의 예시는 영화의 선호도를 완벽하게 나타낼 수 있는 함수를 구할 수 없으므로, 이 조건도 만족한다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:red&quot;&gt;3번 조건&lt;/span&gt;은 너무나 당연한 조건입니다. 예를 들어, 만약 어떤 사람이 태어나서 영화를 한 편도 보지 않았다면 이 사람이 어떤 영화를 좋아하는지 전혀 알 수 없을 것입니다. 이 조건은 셋 중 가장 중요한 조건으로써, 책 제목조차 &lt;strong&gt;Learning From Data&lt;/strong&gt; 로 이 조건을 강조하신 걸 아실 수 있을 것입니다. 영화 추천 대상을 영화를 한번 이상 본 사람들로 한정한다면, 이 조건도 만족하다고 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;따라서, 세 조건을 모두 만족하므로 영화를 추천하는 문제는 기계학습으로 해결할 수 있다고 말할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-05.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 이 문제를 한번 분석해봅시다.&lt;/p&gt;

&lt;p&gt;사람마다 어떤 요소를 선호하는지 위의 그림과 같이 벡터(Vector)로 표현한다고 가정해 보겠습니다. Viewer 벡터에서 각 요소의 동그라미 크기는 이 사람이 해당 요소를 얼마나 좋아하는지에 대한 수치입니다. comedy를 나타내는 원의 크기보다 action을 나타내는 원의 크기가 더 크므로, 이 Viewer는 action영화를 comedy영화보다 더 좋아함을 알 수 있습니다. 영화의 종류 외에도, 배우에 대한 선호도도 영화를 평가하는데 중요한 요소일 것입니다. 이 예시에서는 해당 Viewer가 톰 크루즈를 얼마나 좋아하는가를 예시로 들었습니다.&lt;/p&gt;

&lt;p&gt;비슷한 방법으로 영화들도 이러한 벡터로 표현할 수 있을 것입니다. 이 영화에 comedy 요소는 어느정도인가, action 요소는 어느정도인가, 톰 크루즈가 나오는가 같은 방식으로 말입니다. 이렇게 Viewer와 영화를 각각 벡터로 표현한다면, 이 두 벡터를 비교하여 Viewer가 과연 해당 영화를 좋아할지 아닐지에 대한 평가가 가능합니다. 대표적으로 두 벡터 사이의 Norm (거리)을 계산하는 방법이 있습니다.&lt;/p&gt;

&lt;p&gt;그러나, 이 방법은 단순한 해결 방법의 한 종류일 뿐, 기계학습으로 해결했다고 말할 수 없습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-06.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 어떤 방식으로 해결해야 기계학습으로 해결했다고 말할 수 있을까요?&lt;/p&gt;

&lt;p&gt;이전 슬라이드에서는 Viewer의 벡터와 영화의 벡터가 얼마나 다른가에 따라 선호도를 파악할 수 있다고 했습니다.&lt;/p&gt;

&lt;p&gt;그런데, &lt;strong&gt;“과연 이 차이만으로 Viewer가 어떤 영화를 선호할 지 구분할 수 있을까?”&lt;/strong&gt; 라는 의문이 생깁니다.&lt;/p&gt;

&lt;p&gt;쉽게 설명하기 위해, 예시를 하나 들어보겠습니다. Viewer A, B 두 사람이 존재한다고 가정해보겠습니다. 그리고 정말 우연히도, 이 두 사람이 둘다 comedy를 싫어하고 톰 크루즈를 좋아한다고 가정해봅시다. 그리고 새로운 영화가 나왔습니다. 이 영화는 톰 크루즈가 나오는 comedy 영화라고 가정해봅시다. 그렇다면 A, B 두 사람이 이 영화에 내리는 판단이 같을까요? 조금만 생각해봐도 당연히 아니라는 것을 알 수 있습니다. 예를 들어, A는 톰 크루즈를 너무 좋아해서 비록 싫어하는 comedy 영화라도 높은 평가를 할 수 있고, B는 comedy가 너무 싫어서 아무리 좋아하는 톰 크루즈가 나왔다고 해도 낮은 평가를 내릴 수 있기 때문입니다.&lt;/p&gt;

&lt;p&gt;따라서, 사람들마다 각 요소에 다른 가중치를 갖고 있다는 것을 알 수 있습니다. 어떤 사람은 장르에 더 비중을 둘 수 있고, 어떤 사람은 배우에 더 비중을 둘 수도 있습니다. 이러한 가중치까지 반영하여 각 Viewer가 어떤 영화를 좋아할 지(=높은 평가를 할지) 예측하는 것이 바로 기계학습이라고 할 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;components-of-learning&quot;&gt;Components of Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-07.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 다른 예시를 하나 더 들어봅시다.&lt;/p&gt;

&lt;p&gt;만약 당신이 카드 회사에서 카드를 발급해주는 직원이라고 가정해보겠습니다. 그리고 어떤 사람이 당신에게 카드 발급 신청서를 작성하여 제출했습니다. (그 신청서의 내용은 슬라이드에 나와있는 표와 같다고 생각합시다) 이제 당신은 이 사람에게 카드를 발급해 줄 지, 아니면 거부할지 판단해야 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-08.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 문제를 구체적으로 모델링을 해봅시다. 이전 슬라이드에 나와있는 표의 요소를 Input $\mathbf{x}$로 설정합니다. 즉, $\mathbf{x} =$ (나이, 성별, 연봉, …) 으로 이루어진 벡터입니다. $y$는 해당 Input $\mathbf{x}$에 대한 결과입니다. 카드를 발급해준다면 $y = +1$, 그렇지 않다면 $y = -1$ 입니다. 그리고 Input $\mathbf{x}$와 결과 $y$를 완벽하게 매칭한 함수 $f$가 있다고 가정해봅시다. 3번 슬라이드에서도 언급했듯이, 이 함수는 당연히 구할 수 없습니다. 하지만 이 함수를 최대한 따라가는 것이 목적이므로, 이 함수의 이름을 &lt;span style=&quot;color:red&quot;&gt;Target Function&lt;/span&gt;이라 부릅니다.&lt;/p&gt;

&lt;p&gt;Data는 지금까지 카드를 발급하거나 거부했던 지원자들의 목록입니다. 이를 기반으로 새로운 지원자의 카드 발급 여부를 결정할 것입니다. 이를 통하여 우리의 목적은 ($f$라고 예상되는) Hypothesis function $g$를 도출하는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-09.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이전 슬라이드의 요소들을 도식화하면 위와 같습니다.&lt;/p&gt;

&lt;p&gt;먼저, Target function $f$가 존재하지만(당신의 개인적인 카드 발급 기준) 그걸 구할 수는 없습니다. 하지만 지금까지 카드를 발급해주거나 거부했던 기록들은 모두 이 함수 $f$로부터 도출된 데이터라고 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 기록들을 Training Examples, Training Set, 또는 간단하게 &lt;span style=&quot;color:red&quot;&gt;Sample&lt;/span&gt; 로 부릅니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-10.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hypothesis Set은 이 데이터를 통해 함수 $g$를 구할 수 있는 후보입니다. 가령 모든 지원자들의 카드 발급을 거부한다는 것도 하나의 Hypothesis라고 볼 수 있습니다. 이런 것들을 포함해 모든 Hypothesis들의 집합이 바로 Hypothesis Set입니다. 쉽게 얘기하자면, “정답 후보들의 집합”이라고 이해하시면 됩니다. 그렇다면 이제 정답(이라고 생각되는 것)을 구하기 위해 당신이 갖고있는 데이터와 이런 가설을 묶어 Learning Algorithm을 사용해 Final Hypothesis를 결과물로 도출합니다. Learning Algorithm이라는 것은 앞으로 배울 Perceptron Learning Algorithm이라던가, Neural Network라던가, Support Vector Machine 등을 일컫는 말입니다. 이 두 가지를 합쳐 &lt;span style=&quot;color:red&quot;&gt;Learning Model&lt;/span&gt; 이라 부릅니다.&lt;/p&gt;

&lt;p&gt;당연히 Final Hypothesis는 이들 중에 가장 정확도가 높은(갖고있는 데이터에 가장 잘 들어맞는) 것을 고르는 것이 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;a-simple-model&quot;&gt;A Simple Model&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-11.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이해를 돕기 위해 구체적인 하나의 Model로 예시로 들어보겠습니다. 이 방법은 &lt;span style=&quot;color:red&quot;&gt;Perceptron&lt;/span&gt;이라고 합니다.&lt;/p&gt;

&lt;p&gt;Input $\mathbf{x}$는 앞에서 언급한 바와 같이 고객의 정보를 벡터로 나타낸 것입니다. 이 벡터에는 총 $d$ 종류의 값이 저장되어 있습니다.&lt;/p&gt;

&lt;p&gt;영화 예제에서와 같이, 고객의 정보에서 특히 중요한 요소도 있고, 그렇지 않은 요소도 있을 것입니다. 이렇게 중요도를 표현한 값을 Weight (가중치)라 하고, 이들을 모은 것을 Weight Vector $\mathbf{w}$ 라고 정의하겠습니다. 당연히 모든 고객의 정보에 대한 Weight를 곱해줘야하니, $\mathbf{w}$는 $d$차원의 벡터임을 알 수 있습니다. 즉, $\mathbf{w} = (w_1, w_2, …, w_d)$ 라 쓸 수 있습니다. 고객의 정보에서 이 Weight들을 곱해 하나의 스칼라 값으로 표현해봅시다. 그럼 아래와 같이 정리할 수 있습니다.&lt;/p&gt;

\[w_1 x_1 + w_2 x_2 + ... + w_d x_d = \sum_{i=1}^d w_i x_i\]

&lt;p&gt;이제 이 계산된 스칼라 값을 기준으로 카드를 발급할 지, 거부할 지 결정해야 합니다. 당신이 생각한 기준치를 threshold라고 합시다. 위의 가중치가 반영된 고객 정보의 총 합이 threshold보다 크다면 당신은 카드를 발급해줄 것이고, 아니라면 거부할 것입니다. 이를 하나의 Hypothesis $h$ 라 한다면, 위 슬라이드의 마지막 식처럼 표현할 수 있습니다.&lt;/p&gt;

&lt;p&gt;$\text{sign}$의 의미는 괄호 안의 값이 양수이면 $+1$이고 음수이면 $-1$의 값으로 정한다는 뜻입니다. 예를 들어 $\text{sign}(-0.2) = -1$, $\text{sign}(3.4) = +1$ 입니다. 식에서 빨간색으로 표현된 값들이 구해야 할 값들입니다. ($x_i$는 고객의 데이터로 처음부터 주어진 값이기 때문에 구할 필요가 없습니다)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-12.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;표현을 조금 간단하게 하기 위해, 식을 수정해보겠습니다.&lt;/p&gt;

&lt;p&gt;threshold를 $w_0$으로 표현하겠습니다. 눈썰미가 좋으신 분들은 이전 슬라이드와 비교해보시고 “왜 threshold를 빼는 식이 갑자기 덧셈으로 바뀌냐?” 라고 생각하실겁니다. 하지만 덧셈으로 하든 뻴셈으로 하든 큰 차이는 없습니다. $w_0$를 음수로 설정한다면 어차피 똑같은 식이 되니까요. 굳이 음수로 설정하면서까지 덧셈으로 바꾼 이유는 앞의 Sigma 연산과 합치기 위해서입니다.&lt;/p&gt;

&lt;p&gt;하지만 Weight Vector $\mathbf{w}$와 Input Vector $\mathbf{x}$는 모두 $d$차원 벡터였기 때문에, Sigma 연산과 하나로 합치기 위해서는 $x_0$이 필요합니다. $w_0$은 어차피 threshold 값이라 $x_0$가 의미 없으므로, 편의상 $x_0 = 1$로 설정합니다. 그렇게 되면 결국 괄호 안의 Sigma 연산은 $w_0 x_0 + w_1 x_1 + … + w_d x_d$가 되므로 두 벡터 $\mathbf{w}$와 $\mathbf{x}$의 내적(Inner Product)라 할 수 있을 것입니다.&lt;/p&gt;

&lt;p&gt;이를 행렬(Matrix)로 표현한다면, 위 식의 마지막 식 처럼 $\mathbf{w}$의 전치행렬(Transpose Matrix)과 $\mathbf{x}$의 곱으로 표현할 수 있습니다.&lt;/p&gt;

&lt;p&gt;방금까지 유도해낸 Hypothesis $h$ (Perceptron)는 결국 두 벡터(또는 행렬)의 곱으로 이루어진 선형(Linear)식이기 때문에 이 방법으로 데이터를 완벽하게 구분하려면(카드를 발급해줄 사람과 거부해줄 사람을 구분하려면) 반드시 데이터가 선형 구분이 가능해야 합니다. (오른쪽 linearly separable data 그림을 참고하시면 이해가 편합니다.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-13.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 이 Perceptron에서 가중치 벡터 $\mathbf{w}$를 구하는 것이 목적이 되었습니다.
여기서는 간단한 알고리즘인 Perceptron Learning Algorithm (PLA)을 설명합니다.&lt;/p&gt;

&lt;p&gt;알고리즘을 시작하기 전에, 가중치 벡터 $\mathbf{w}$는 임의의 값으로 초기화합니다. (일반적으로 영벡터로 초기화하는 것이 가장 무난합니다)&lt;/p&gt;

&lt;p&gt;방금까지 정한 Perceptron Hypothesis $h$ 에 기존에 갖고있던 Training Set을 하나씩 대입합니다. (이 Training Set은 과거에 당신이 카드를 발급해주거나 거부했던 데이터이기 때문에 올바른 $y$값까지 존재합니다) 대입을 했을 때 올바른 결과가 나오는 경우 (즉, $sign(\mathbf{w}^T \mathbf{x}_n) = y_n$인 경우)에는 그냥 넘어갑니다. 하지만 만약 Training Data를 넣었을 때 다른 경우가 나온다면 (즉, $sign(\mathbf{w}^T \mathbf{x}_n) \neq y_n$인 경우) 아래와 같이 가중치 벡터 $\mathbf{w}$를 업데이트 합니다.&lt;/p&gt;

\[\mathbf{w} = \mathbf{w} + y_n \mathbf{x}_n\]

&lt;p&gt;그렇게 하면 위 슬라이드의 오른쪽 그림과 같이 Weight Vector $\mathbf{w}$의 방향이 수정됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-14.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이를 아까 11번 슬라이드에서 보았던 그림처럼 표현한다면 위 슬라이드의 오른쪽 그림과 같습니다. 분홍색 선이 현재의 가중치 벡터 $\mathbf{w}$의 위치입니다. (위 슬라이드 식의 빨간색 $\mathbf{w}$를 의미합니다) 동그라미 친 파란색 (+) 데이터가 Perceptron 식에 대입이 되었다고 가정해봅시다. 그렇다면 이 (+) 데이터는 잘못 분류된(misclassified) 데이터이기 때문에 (양의 값을 가지는 Output인데 음의 값을 가지는 Output들과 같이 분류되어 있으므로) 가중치 벡터 $\mathbf{w}$의 업데이트가 필요합니다. 따라서 현재의 분홍색 선이 왼쪽방향으로 살짝 휘게 되어 새로운 가중치 벡터 $\mathbf{w}$가 나오게 됩니다. (위 슬라이드 식의 파란색 $\mathbf{w}$를 의미합니다)&lt;/p&gt;

&lt;p&gt;이 과정이 반복해서 $N$개의 모든 데이터가 올바르게 분류된다면, 이 알고리즘이 끝나게 되고 주어진 데이터를 분류할 수 있는 가중치 벡터 $\mathbf{w}$가 결과물로 나오게 됩니다.&lt;/p&gt;

&lt;p&gt;이 알고리즘이 왜 선형 분류가 가능한 데이터를 정확하게 분류할 수 있는지 의문을 가지시는분도 분명히 계실 것입니다. 당연한 의문입니다. 직관적으로는 왜 이 방법이 분류가 되는지 이해하기 어려워 증명이 필요하기 때문입니다. 다만 여기에 이 증명까지 싣게 되면 분량이 너무 늘어나기 때문에, 대표적인 2개의 증명이 나와있는 링크만 남기겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Haim Sompolinsky 교수님의 증명 [&lt;a href=&quot;http://web.mit.edu/course/other/i2course/www/vision_and_learning/perceptron_notes.pdf&quot;&gt;pdf&lt;/a&gt;]&lt;/li&gt;
  &lt;li&gt;Michael Collins 교수님의 증명 [&lt;a href=&quot;http://www.cs.columbia.edu/~mcollins/courses/6998-2012/notes/perc.converge.pdf&quot;&gt;pdf&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 외에도 구글에 검색해보시면 여러 증명 방법들이 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;types-of-learning&quot;&gt;Types of Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-15.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 기계학습에 어떤 종류가 존재하는지 하나씩 살펴보겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-16.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;기본적으로 학습의 전제는 “관찰된 결과들을 사용하여 근본적인 과정을 밝혀낸다” 입니다. 여기서 근본적인 과정(underlying process)이 의미하는 것은 어떤 데이터를 출력하는지에 대한 확률 분포(probability distribution)이고, 관찰된 결과(a set of observations)란 그 확률 분포로부터 생성된 데이터(샘플)라는 뜻입니다. 이 전제가 굉장히 방대하기 때문에, 이 전제를 만족하는 방법은 수많은 종류가 있습니다.&lt;/p&gt;

&lt;p&gt;여기서는 크게 3가지로 나누어 Supervised Learning, Unsupervised Learning, 그리고 Reinforcement Learning이 소개되어 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-17.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:red&quot;&gt;Supervised Learning&lt;/span&gt; (지도학습)이란 사람이 데이터를 학습시킬 때 Input $\mathbf{x}$와 정답 Label $y$를 주고 학습시키는 방법입니다.&lt;/p&gt;

&lt;p&gt;슬라이드의 예제에서는 자판기에서 사용되는 동전 분류 방법을 제시하고 있습니다. 동전은 종류에 따라(각인되어있는 액수에 따라) 각각 크기와 질량이 다릅니다. 다만 같은 액수의 동전이라고 해도 이것들이 완벽하게 같지는 않습니다. 왜냐하면 동전은 사용되면서 이물질이 묻을 수도 있고, 닳을 수도 있기 때문입니다. 이 예제에서 지도학습을 사용한다면 자판기에 동전을 넣어주면서 “이것이 10센트 동전이다”, “이것이 25센트 동전이다”라고 정답을 입력해주는 것입니다. 이렇게 되면 위 슬라이드의 왼쪽 그림과 같이 각 동전의 크기와 질량 분포를 알 수 있고, 이를 사용하여 오른쪽 그림과 같이 동전을 분류할 수 있는 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-18.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다음으로 &lt;span style=&quot;color:red&quot;&gt;Unsupervised Learning&lt;/span&gt; (비지도학습)은 지도학습과는 다르게 Input $\mathbf{x}$만 주고 이에 대한 정답 $y$를 주지 않는 방법입니다. 자판기 예제로 돌아가보면, 동전의 크기와 질량을 기준으로 위의 그래프와 같이 명확하게 구분할 수는 있지만, 어느 분포가 어느 액수의 동전인지를 구분할 수 없습니다. 언뜻 보면 왜 지도학습을 놔두고 비지도학습을 사용하나 의문이 들 수도 있습니다만, 일반적으로 정답이 주어져 있는 데이터보다 주어져 있지 않은 데이터가 훨씬 많으므로 이 방법을 연구하는 것도 상당히 중요합니다. 비지도학습은 주로 Clustering (군집화)을 통해 구현합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-19.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;span style=&quot;color:red&quot;&gt;Reinforcement Learning&lt;/span&gt; (강화학습)은 지도학습이나 비지도학습과는 전혀 다른 구조를 갖고 있습니다. 일단 이 방법도 앞의 두 방법과 마찬가지로 Input $\mathbf{x}$가 주어집니다. 그러나 이 Input에 대해 정답이 주어지는 것이 아니라 이것이 얼마나 괜찮은지에 대한 평가를 하게 됩니다.&lt;/p&gt;

&lt;p&gt;이해를 돕기 위해 재밌는 예시를 하나 들겠습니다. 아기들은 손에 잡히는건 뭐든지 입에 넣으려고 합니다. 젖병도 입에 넣고, 사탕도 입에 넣고, … 심지어 신발까지 입에 넣습니다. 이렇게 하나하나 입에 넣어보다가 먹을 수 있는 것들(젖병, 사탕 등)은 긍정적인 평가를 내립니다. 따라서 학습을 한 후 동일한 물건을 발견했을 때엔 역시 입에 넣게 됩니다. 하지만 신발을 입에 넣고 나서는 이게 먹을 수 없는 것이란걸 깨닫습니다. 이런 경우 애기 스스로 신발에 대한 부정적인 평가를 내리고, 다음에 또 다시 신발이 손에 잡힌다면 그 때는 입에 넣지 않는 판단을 하게 됩니다.&lt;/p&gt;

&lt;p&gt;이러한 원리 때문에 강화학습의 경우 게임과 같은 문제를 해결하는데 가장 널리 이용되고 있습니다. 대표적으로 한창 화제가 되었던 알파고도 강화학습을 이용하여 구현한 프로그램입니다. (물론 강화학습’만’ 사용한 것은 아닙니다)&lt;/p&gt;

&lt;p&gt;현재 가장 Hot한 방법으로써 많은 논문에서 언급되고 있습니다. 다만, 본 교재에서는 전반적인 기계학습에 대한 내용만 다루고 있어 이후로는 본 교재나 강의에서 강화학습에 대한 언급은 없습니다. 제 연구분야 중 하나가 강화학습이기 때문에, 추후 강화학습 교재만을 따로 정리하여 게시하도록 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;a-learning-puzzle&quot;&gt;A Learning Puzzle&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/1. The Learning Problem/ML 01-20.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;지금까지 배운 내용을 토대로 간단한 퍼즐 문제를 풀어보도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;위 3개의 Data는 -1로 분류되었고, 아래 3개의 Data는 +1로 분류되어 있습니다.&lt;/p&gt;

&lt;p&gt;그럼 맨 아래의 퍼즐은 무엇으로 분류할 수 있을까요?&lt;/p&gt;

&lt;p&gt;정답은 &lt;strong&gt;“이 데이터만으로는 +1인지 -1인지 확실하게 결정할 수 없다”&lt;/strong&gt; 입니다. 앞부분에서 언급했다시피 Target function $f$는 아무도 모르는 것이기 때문입니다. 주어진 데이터만으로 아래의 퍼즐을 분류하기에는 -1로 분류할 수 있는 근거도 있고, +1로 분류할 수 있는 근거도 있습니다. 만약 첫번째 칸이 색칠되어 있는게 -1로 분류하는 기준이다 라고 하면 문제의 퍼즐은 -1로 분류될 것이고, 또는 대칭되어 있는 퍼즐이 +1이다 라고 하면 문제의 퍼즐은 +1로 분류할 수 있기 때문입니다.&lt;/p&gt;

&lt;p&gt;그렇다면 데이터를 가지고 학습을 하는건 불가능한 것이 아닌가 하는 의문이 생기게 됩니다. 그 답은 다음 챕터에 이어서 설명하도록 하겠습니다.&lt;/p&gt;

&lt;p&gt;이번 챕터는 여기까지입니다. 읽어주셔서 감사합니다.&lt;/p&gt;</content><author><name>Joonsu Ryu</name></author><category term="studies" /><category term="machine learning" /><summary type="html"></summary></entry><entry><title type="html">Introduction</title><link href="http://localhost:4000/studies/introduction/" rel="alternate" type="text/html" title="Introduction" /><published>2019-07-12T00:00:00+09:00</published><updated>2019-07-12T00:00:00+09:00</updated><id>http://localhost:4000/studies/introduction</id><content type="html" xml:base="http://localhost:4000/studies/introduction/">&lt;p&gt;안녕하세요, 오늘은 Machine Learning 카테고리에 대해 말씀드리려 합니다. 이 카테고리에는 제가 예전에 기계학습을 공부하며 이해한 내용을 챕터별로 정리하는 식으로 진행하려고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;textbook&quot;&gt;Textbook&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/0. Introduction/ML 00-01.png&quot; alt=&quot;&quot; width=&quot;300&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;작성된 글의 기반은 위의 사진에 나와있는 Learning From Data라는 교재입니다. 책의 저자이신 Abu-Mostafa 교수님은 칼텍 소속으로 실제로 Machine Learning 수업을 강의하실 때 이 교재를 사용하는 것으로 알고 있습니다. 강의자료는 모두 &lt;a href=&quot;https://work.caltech.edu/textbook.html&quot;&gt;Caltech&lt;/a&gt;에서 무료로 다운로드 받을 수 있고 강의 영상까지 &lt;a href=&quot;https://www.youtube.com/watch?v=mbyG85GZ0PI&amp;amp;list=PLD63A284B7615313A&amp;amp;ab_channel=caltech&quot;&gt;Caltech Youtube&lt;/a&gt;에 게시되어 있기 때문에 독학하시기에 좋은 교재라고 생각합니다. 강의 영상이 영어로만 나오고 따로 한글 자막이 존재하는 것은 아니지만, 영어 자막이 제공되기 때문에 영어 듣기에 익숙하지 않은 분들도 영상을 보는데 크게 문제가 있지는 않으실 것이라 생각됩니다.&lt;/p&gt;

&lt;p&gt;일반적으로 언급이 많이 되는 교재로 Murphy의 &lt;a href=&quot;https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020/ref=sr_1_1?crid=194TGT6A3GLWG&amp;amp;keywords=Machine+Learning+%3A+A+Probabilistic+Perspective&amp;amp;qid=1677073873&amp;amp;sprefix=machine+learning+a+probabilistic+perspective%2Caps%2C234&amp;amp;sr=8-1&quot;&gt;Machine Learning : A Probabilistic Perspective&lt;/a&gt; 교재나 Bishop의 &lt;a href=&quot;https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738/ref=sr_1_1?crid=12XEZA5LW172R&amp;amp;keywords=pattern+recognition+%26+machine+learning&amp;amp;qid=1677074201&amp;amp;sprefix=machine+learning+a+probabilistic+perspective%2Caps%2C1023&amp;amp;sr=8-1&quot;&gt;Pattern Recognition &amp;amp; Machien Learning&lt;/a&gt; 교재가 있습니다만, 책의 두께도 무지막지할 뿐더러 내용도 만만치 않기 때문에 기계학습에 입문하시기에는 적절하지 않을 것이라 생각합니다. (저는 Murphy 교재나 Bishop 교재는 통독을 하기 보다는 사전처럼 모르는 내용이 있을 때 찾아보는 용도로 사용하고 있습니다) 대신 제가 추천드리는 Learning From Data 교재는 책이 얇고 각 챕터별 길이가 그다지 길지 않아 읽는 지루함을 좀 덜을 수 있는 장점이 있습니다.&lt;/p&gt;

&lt;p&gt;물론 그렇다고 이 책이 완벽한 것은 아닙니다. 책이 짧은 만큼 Murphy 책이나 Bishop 책과 비교하면 설명이 미흡한 부분이 존재하고, 심지어는 강의자료에는 있지만 책에는 없는 내용까지 존재합니다. 본 교재의 칼텍 강의자료/유튜브 강의 영상을 보시면 Neural Networks (Lecture 10), Support Vector Machines (Lecture 14), Kernel Methods (Lecture 15), Radial Basis Functions (Lecture 16) 강의가 분명 존재하지만, 책에는 이 부분들이 생략되어 있습니다. 정말 아쉽게도 이 부분은 강의자료와 강의영상만 보시면서 공부하셔야 합니다. 사실 한 챕터당 약 100분 정도만 강의하시는데 이정도 분량이면 충분히 책에 넣을만 하지 않았을까라는 의문이 들기도 합니다만…&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/0. Introduction/ML 00-02.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;책이 얇기 때문에 하드커버임에도 약 4만원 정도면 구할 수 있습니만, 이 교재는 국내에서 많이 유명한 책이 아니다보니 구하기가 어렵습니다. 이 책을 수입해서 파는 서점이 거의 없어 아마존 등을 통해 직구하셔야 합니다. 강의 자료도 제공되고 강의 영상의 질도 좋기 때문에 정 구하기 어려우시면 책을 구입하시지 않으셔도 되지만, Neural Networks와 Support Vector Machines 부분은 책을 구입하시게 되면 책에 나와있는 비밀 계정(?)으로 pdf파일을 제공해줍니다.&lt;/p&gt;

&lt;p&gt;장점이 있는 만큼 이런저런 단점도 존재하지만 그나마 짧고 쉬운 책으로 기계학습을 입문하시기에는 Learning From Data 교재가 최고라고 생각합니다. 해외에서는 유명한지 구글링을 좀 해보시면 교재의 프로그래밍 연습문제도 Github에 많이 올라와 있어서 참고 자료도 풍부한 편입니다. 다만 이 책으로는 어디까지나 입문으로 생각하셔야지, 이 책 한 권으로 기계학습을 마스터하겠다! 라는 생각을 하시면 조금 곤란합니다. 앞서 소개드린 Murphy 교재나 Bishop 교재에 비해 생략되거나 간소화된 내용이 많아 제대로 공부하시기 위해서는 다른 교재 또한 참고하시는 것을 추천드립니다.&lt;/p&gt;

&lt;h2 id=&quot;outline-of-the-course&quot;&gt;Outline of the course&lt;/h2&gt;

&lt;p&gt;공부하실 때 주의하실 점은 책의 순서와 칼텍의 강의자료의 순서가 조금 다릅니다. (대표적으로 Linear Model 부분) 다만 강의자료의 내용이 교재보다 커버하는 부분이 넓다 보니 제가 작성할 글은 칼텍의 강의자료를 기준으로 할 예정입니다. 강의자료의 구성은 아래 그림과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Machine Learning/0. Introduction/ML 00-03.png&quot; alt=&quot;&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;강의자료는 위와 같이 총 18개의 챕터로 이루어져 있습니다. 빨간색 챕터는 수학적인 내용 위주, 파란색 챕터는 기술적인 내용 위주로 구성되어 있으며 초록색 챕터는 개념과 용어에 대해 설명하는 부분입니다. 아무래도 수학적인 부분 때문에 걱정이 되시는 분들도 계실 텐데요, 학부에서 미적분학, 선형대수학, 공업수학, 통계학 등을 익히셨다면 이해하는데 큰 문제는 없습니다. 강의 중 벡터 연산 같이 복잡한 부분도 있으나, 보통 증명 부분에서 많이 나오고, 증명 부분은 굳이 전부 이해하지 않아도 괜찮습니다.&lt;/p&gt;

&lt;p&gt;다음 포스트부터 한 장(Chapter)씩 다루도록 하겠습니다.&lt;/p&gt;</content><author><name>Joonsu Ryu</name></author><category term="studies" /><category term="machine learning" /><summary type="html">안녕하세요, 오늘은 Machine Learning 카테고리에 대해 말씀드리려 합니다. 이 카테고리에는 제가 예전에 기계학습을 공부하며 이해한 내용을 챕터별로 정리하는 식으로 진행하려고 합니다.</summary></entry></feed>